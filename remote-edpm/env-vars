# Export all variables
set -a

###############################################################################
# Variables you have to modify

# Your pull secret to get CRC
PULL_SECRET=/home/geguileo/work/pull-secret

# The directory were we have the install_yamls repository
INSTALL_YAMLS_DIR=/home/geguileo/work/install_yamls

# The remote EDPM host address and SSH arguments to connect to it
REMOTE_EDPM_IP=192.168.1.13

# User for Ansible to use on the edpm host. When undefined defaults to cloud-admin. Gets created if it doesn't exist.
SSH_USER=geguileo

# SSH args to connect from this host to the remote.  Can be different user from SSH_USER
SSH_ARGS="-o IdentityFile=~/.ssh/id_rsa -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o User=${SSH_USER}"

# For PCI passthrough we need to know the PCI vendor and product IDs
# NVIDIA => 10de    AMD => 1002
NVIDIA_VENDOR_ID='10de'
AMD_VENDOR_ID='1002'
INTEL_VENDOR_ID='8086'
  # We can set them both manually here, for example for AMD MI210
PCI_VENDOR_ID=$AMD_VENDOR_ID
PCI_PRODUCT_ID='740f'
  # For example for NVIDIA RTX4090
  # PCI_VENDOR_ID='10de'
  # PCI_PRODUCT_ID='2684'
  # Or we could just set the PCI_VENDOR_ID as above and automatically get the producing ID with
  # PCI_PRODUCT_ID=$(ssh ${SSH_ARGS} ${REMOTE_EDPM_IP} "sudo dnf -y install pciutils && lspci -n |grep ${PCI_VENDOR_ID} | cut -f3 -d' '| cut -f2 -d: | head -n1")


###############################################################################
# Variables you should check

# The subnet network that will be used to connect all EDPM nodes with the OCP cluster
IP_ADDRESS_PREFIX=192.168.140

# VM resources for the OCP CRC VM
CRC_CPUS=12
CRC_RAM=24
CRC_DISK=100


###############################################################################
# Variables that should be fine as they are
CRC_VERSION=2.41.0

# This is the OCP node (`oc get node`) name
OCP_NODE_NAME=crc

# This is the name that will be used for the bridge and libvirt network
VIRT_NETWORK=rhoso

# MTU value to account for the all the overhead
# MTU=1450 ==> Only using geneve tunnel on same network
# MTU=1310 ==> When using geneve tunnel on top of VPN tunnel
MTU=1310

# Template used for the RHOSO control plane
CTL_TEMPLATE=./templates/kustomization-nw-isolation-no-cinder.yaml

# Number of the EDPM node so we can assign IPs and other things based on it
EDPM_NODE=0

# Geneve tunner ID
GNV_ID="100${EDPM_NODE}"

# The name we'll use for the tunnel when creating it locally
TUN_NAME="gnv${EDPM_NODE}"

# Local IP that remote host should use to establish the Geneve tunnel.
# When empty we'll try to get it based on the remote IP
TUN_LOCAL_IP=

# SSH private key file for Ansible to connect to edpm. ${SSH_KEY_FILE}.pub must exist next to it.
# Will generate one if empty.
SSH_KEY_FILE=

NETCONFIG_TEMPLATE="./templates/network_v1beta1_netconfig.yaml"

# This will be added after the OCP DNS resolver. Needed to not lose local DNS resolution if we have it.
INET_DNS_SERVER=1.1.1.1

# For now we only support `intel` this is used for the kernel args and enabling IOMMU
EDPM_CPU=intel
# If you want to add kernel args like hugepages=1GB
EDPM_ADD_KERNEL_ARGS=

# Add conditional on EDPM_CPU once we support non intel CPUs in this script
IOMMU_KERNEL_ARGS="intel_iommu=on iommu=pt vfio_pci.ids=${PCI_VENDOR_ID}:${PCI_PRODUCT_ID} rd.driver.pre=vfio_pci modules-load=vfio,vfio-pci,vfio_iommu_type1,vfio_pci_vfio_virqfd"

NVIDIA_KERNEL_ARGS="noveau.blacklist=1 nvidia.blacklist=1 nvidia-drm.blacklist=1 nvidia-modeset.blacklist=1 nvidia-uvm.blacklist=1 rd.driver.blacklist=nouveau,nvidia,nvidia-drm,nvidia-modeset,nvidia-uvm"
AMD_KERNEL_ARGS="amdgpu.blacklist=1 radeon.blacklist=1 rd.driver.blacklist=amdgpu,radeon"
INTEL_KERNEL_ARGS="i915.blacklist=1 rd.driver.blacklist=i915"

###############################################################################
# Functions


[ -n "${SSH_USER}" ] || SSH_USER=cloud-admin
[ -n "${SSH_KEY_FILE}" ] || SSH_KEY_FILE="${INSTALL_YAMLS_DIR}/out/edpm/ansibleee-ssh-key-id_rsa"

# Add conditional on EDPM_CPU once we support non intel CPUs in this script
case "${PCI_VENDOR_ID}" in
    "${NVIDIA_VENDOR_ID}")
      GPU_KERNEL_ARGS="${NVIDIA_KERNEL_ARGS}"
      ;;
    "${AMD_VENDOR_ID}")
      GPU_KERNEL_ARGS="${AMD_KERNEL_ARGS}"
      ;;
    "${INTEL_VENDOR_ID}")
      GPU_KERNEL_ARGS="${INTEL_KERNEL_ARGS}"
      ;;
    *)
      GPU_KERNEL_ARGS="${NVIDIA_KERNEL_ARGS} ${AMD_KERNEL_ARGS} ${INTEL_KERNEL_ARGS}"
      ;;
esac

EDPM_KERNEL_ARGS="${IOMMU_KERNEL_ARGS} ${GPU_KERNEL_ARGS} ${EDPM_ADD_KERNEL_ARGS}"


# Get the local IP that the remote will use to connect
if [ -z "${TUN_LOCAL_IP}" ]; then
    IP_NM=$(ip -o a |grep "${REMOTE_EDPM_IP%.*}\."|awk '{print $4}')
    TUN_LOCAL_IP="${IP_NM%/*}"
fi

if [ -z "${TUN_LOCAL_IP}" ]; then
    echo "Error: Cannot determine the IP the remote node tunnel should connect to. Please set TUN_LOCAL_IP"
    return 1
fi

DEFAULT_SSH_KEY_FILE="${INSTALL_YAMLS_DIR}/out/edpm/ansibleee-ssh-key-id_rsa"

if [ -n "${SSH_KEY_FILE}" ] && [ "${SSH_KEY_FILE}" != "${DEFAULT_SSH_KEY_FILE}" ] && ! ( [ -f "${SSH_KEY_FILE}" ] && [ -f "${SSH_KEY_FILE}.pub" ] ); then
    echo "Error: '${SSH_KEY_FILE}' or '${SSH_KEY_FILE}.pub' missing"
    return 1
fi


function generate_key {
    OUTPUT_DIR="${INSTALL_YAMLS_DIR}/out/edpm"

    SSH_REL_PATH="$(realpath -m --relative-to=${OUTPUT_DIR} ${SSH_KEY_FILE})"

    OUTPUT_DIR="${OUTPUT_DIR}" \
        SSH_KEY_FILE="${SSH_REL_PATH}" \
        ${INSTALL_YAMLS_DIR}/devsetup/scripts/gen-ansibleee-ssh-key.sh
}

function gen_edpm_config {
    sed "s/\${VENDOR_ID}/${PCI_VENDOR_ID}/g;s/\${PRODUCT_ID}/${PCI_PRODUCT_ID}/g" ./templates/nova-compute.conf > ./out/nova-compute.conf

    mkdir -p out/preprovisioned

    BASE_DATAPLANE_YAML="$(realpath -m --relative-to=$(realpath ./out/preprovisioned) ${INSTALL_YAMLS_DIR}/out/operator/openstack-operator/config/samples/dataplane/base)"

    sed "s#\${BASE_DATAPLANE_YAML}#${BASE_DATAPLANE_YAML}#g;s#\${KERNEL_ARGS}#${EDPM_KERNEL_ARGS}#g" ./templates/preprovisioned/kustomization.yaml > ./out/preprovisioned/kustomization.yaml
    sed "s/\${TUN_IP}/${TUN_LOCAL_IP}/g;s/\${GNV_ID}/${GNV_ID}/g;s/\${TUN_NAME}/${TUN_NAME}/g;s/\${DNS_SERVER}/${INET_DNS_SERVER}/g;s/\${MTU}/${MTU}/g" \
        ./templates/preprovisioned/tunneling.yaml > ./out/preprovisioned/tunneling.yaml
    sed "s/\${DNS_SERVER}/${INET_DNS_SERVER}/g" ./templates/preprovisioned/os-net-config-template.yaml > ./out/preprovisioned/os-net-config-template.yaml
}


function wait_mc_applied {
  echo 'Waiting for the cluster to begin updating'
  while ! oc wait mcp master --for condition=Updating; do sleep 10; done
  echo 'Waiting for the cluster to finish'
  while ! oc wait mcp master --for condition=Updated; do sleep 10; done
}


function change_cluster_mtu {
    # We need to set the "machine" part without changes or changes will be ignored
    echo 'Requesting the migration of the cluster MTU'
    CLUSTER_MTU="$((${MTU}-100))"
    oc patch Network.operator.openshift.io cluster --type=merge \
        --patch "{\"spec\": { \"migration\": { \"mtu\": { \"network\": { \"from\": 1400, \"to\": ${CLUSTER_MTU} }, \"machine\": {\"from\": 1500, \"to\": 1500} } } } }"

    wait_mc_applied

    echo 'Finalizing the migration of the cluster MTU'
    oc patch Network.operator.openshift.io cluster --type=merge --patch "{\"spec\": { \"migration\": null, \"defaultNetwork\":{ \"ovnKubernetesConfig\": { \"mtu\": ${CLUSTER_MTU} }}}}"

    wait_mc_applied
}
