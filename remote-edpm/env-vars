# Export all variables
set -a

###############################################################################
# Variables you have to modify

# Your pull secret to get CRC
PULL_SECRET=$(realpath ~/pull-secret)

# The directory were we have the install_yamls repository
INSTALL_YAMLS_DIR=$(realpath ~/install_yamls)

# The remote EDPM host address and SSH arguments to connect to it
REMOTE_EDPM_IP=192.168.1.13

# User for Ansible to use on the edpm host. When undefined defaults to cloud-admin. Gets created if it doesn't exist.
SSH_USER=geguileo

# SSH args to connect from this host to the remote.  Can be different user from SSH_USER
SSH_ARGS="-o IdentityFile=~/.ssh/id_rsa -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o User=${SSH_USER}"

# For PCI passthrough we need to know the PCI vendor and product IDs
# NVIDIA => 10de    AMD => 1002
NVIDIA_VENDOR_ID='10de'
AMD_VENDOR_ID='1002'
INTEL_VENDOR_ID='8086'
  # We can set them both manually here, for example for AMD MI210
PCI_VENDOR_ID=$AMD_VENDOR_ID
PCI_PRODUCT_ID='740f'
# We also need to know if the device is SR-IOV capable. If we know it we can
# set it to true or false, otherwise it will be automatically detected.
SRIOV_CAPABLE=
  # For example for NVIDIA RTX4090
  # PCI_VENDOR_ID='10de'
  # PCI_PRODUCT_ID='2684'
  # Or we could just set the PCI_VENDOR_ID as above and automatically get the producing ID with
  # PCI_PRODUCT_ID=$(ssh ${SSH_ARGS} ${REMOTE_EDPM_IP} "sudo dnf -y install pciutils && lspci -n |grep ${PCI_VENDOR_ID} | cut -f3 -d' '| cut -f2 -d: | head -n1")


###############################################################################
# Variables you should check

# The subnet network that will be used to connect all EDPM nodes with the OCP cluster
IP_ADDRESS_PREFIX=192.168.140

# VM resources for the OCP CRC VM
CRC_CPUS=12
CRC_RAM=24
CRC_DISK=100

# Whether to use the upstream bits or Red Hat specific
USE_UPSTREAM=true

# We can set the Openstack Image if we want to override the defaults that are set automaticallly below based on USE_UPSTREAM
OPENSTACK_IMG=

# When setting USE_UPSTREAM to a non "true" value we need to set subscription manager credentials (SM_*) and RH registry credentials (RHR_*)
SM_USERNAME=
SM_PASSWORD=
# These default to their SM_ counterparts later on when empty
RHR_USERNAME=
RHR_PASSWORD=

###############################################################################
# Variables that should be fine as they are
CRC_VERSION=2.41.0
OCP_VERSION=4.16

# This is the OCP node (`oc get node`) name
OCP_NODE_NAME=crc

# This is the name that will be used for the bridge and libvirt network
VIRT_NETWORK=rhoso

# MTU value to account for the all the overhead
# MTU=1450 ==> Only using geneve tunnel on same network
# MTU=1310 ==> When using geneve tunnel on top of VPN tunnel
MTU=1310
VLAN_MTU=$(( $MTU - 4 ))

# Template used for the RHOSO control plane
CTL_TEMPLATE=./templates/kustomization-nw-isolation-no-cinder.yaml

# Number of the EDPM node so we can assign IPs and other things based on it
EDPM_NODE=0

# Geneve tunner ID
GNV_ID="100${EDPM_NODE}"

# The name we'll use for the tunnel when creating it locally
TUN_NAME="gnv${EDPM_NODE}"

# Local IP that remote host should use to establish the Geneve tunnel.
# When empty we'll try to get it based on the remote IP
TUN_LOCAL_IP=

# SSH private key file for Ansible to connect to edpm. ${SSH_KEY_FILE}.pub must exist next to it.
# Will generate one if empty.
SSH_KEY_FILE=

NETCONFIG_TEMPLATE="./templates/network_v1beta1_netconfig.yaml"

# This will be added after the OCP DNS resolver. Needed to not lose local DNS resolution if we have it.
INET_DNS_SERVER=1.1.1.1

# For now we only support `intel` this is used for the kernel args and enabling IOMMU
EDPM_CPU=intel
# If you want to add kernel args like hugepages=1GB
EDPM_ADD_KERNEL_ARGS=

# Add conditional on EDPM_CPU once we support non intel CPUs in this script
IOMMU_KERNEL_ARGS="intel_iommu=on iommu=pt vfio_pci.ids=${PCI_VENDOR_ID}:${PCI_PRODUCT_ID} rd.driver.pre=vfio_pci modules-load=vfio,vfio-pci,vfio_iommu_type1,vfio_pci_vfio_virqfd"

NVIDIA_KERNEL_ARGS="noveau.blacklist=1 nvidia.blacklist=1 nvidia-drm.blacklist=1 nvidia-modeset.blacklist=1 nvidia-uvm.blacklist=1 rd.driver.blacklist=nouveau,nvidia,nvidia-drm,nvidia-modeset,nvidia-uvm"
AMD_KERNEL_ARGS="amdgpu.blacklist=1 radeon.blacklist=1 rd.driver.blacklist=amdgpu,radeon"
INTEL_KERNEL_ARGS="i915.blacklist=1 rd.driver.blacklist=i915"

###############################################################################
# Functions

[ -n "${SSH_USER}" ] || SSH_USER=cloud-admin
[ -n "${SSH_KEY_FILE}" ] || SSH_KEY_FILE="${INSTALL_YAMLS_DIR}/out/edpm/ansibleee-ssh-key-id_rsa"

# Default the Red hat registry usernames and passwords to the same as the subscription manager's
[ -n "${RHR_USERNAME}" ] || RHR_USERNAME=${SM_USERNAME}
[ -n "${RHR_PASSWORD}" ] || RHR_PASSWORD=${SM_PASSWORD}


if [ "${USE_UPSTREAM}" == 'true' ]; then
    DATAPLANE_SKIP_REPO_SETUP=
    DATAPLANE_REGISTRY_URL=quay.io/podified-antelope-centos9
    DATAPLANE_CONTAINER_TAG=current-podified
    DATAPLANE_CONTAINER_PREFIX=openstack
else
    if [ -z "${SM_USERNAME}" ] || [ -z "${SM_PASSWORD}" ] || [ -z "${RHR_USERNAME}" ] || [ -z "${RHR_PASSWORD}" ]; then
        echo "Error: To use Red Hat operators you need to set the SM_USERNAME, SM_PASSWORD, RHR_USERNAME and RHR_PASSWORD variables"
        return 1
    fi
    DATAPLANE_SKIP_REPO_SETUP=true
    DATAPLANE_REGISTRY_URL=
    DATAPLANE_CONTAINER_TAG=
    DATAPLANE_CONTAINER_PREFIX=
fi

# Automatically set the openstack operator image
if [[ -z "${OPENSTACK_IMG}" ]]; then
    if [[ "${USE_UPSTREAM}" == 'true' ]]; then
        OPENSTACK_IMG=quay.io/openstack-k8s-operators/openstack-operator-index:latest
    else
        OPENSTACK_IMG=registry.redhat.io/redhat/redhat-operator-index:v4.16
    fi
fi

# Add conditional on EDPM_CPU once we support non intel CPUs in this script
case "${PCI_VENDOR_ID}" in
    "${NVIDIA_VENDOR_ID}")
      GPU_KERNEL_ARGS="${NVIDIA_KERNEL_ARGS}"
      ;;
    "${AMD_VENDOR_ID}")
      GPU_KERNEL_ARGS="${AMD_KERNEL_ARGS}"
      ;;
    "${INTEL_VENDOR_ID}")
      GPU_KERNEL_ARGS="${INTEL_KERNEL_ARGS}"
      ;;
    *)
      GPU_KERNEL_ARGS="${NVIDIA_KERNEL_ARGS} ${AMD_KERNEL_ARGS} ${INTEL_KERNEL_ARGS}"
      ;;
esac

EDPM_KERNEL_ARGS="${IOMMU_KERNEL_ARGS} ${GPU_KERNEL_ARGS} ${EDPM_ADD_KERNEL_ARGS}"


# Get the local IP that the remote will use to connect
if [ -z "${TUN_LOCAL_IP}" ]; then
    IP_NM=$(ip -o a |grep "${REMOTE_EDPM_IP%.*}\."|awk '{print $4}')
    TUN_LOCAL_IP="${IP_NM%/*}"
fi

if [ -z "${TUN_LOCAL_IP}" ]; then
    echo "Error: Cannot determine the IP the remote node tunnel should connect to. Please set TUN_LOCAL_IP"
    return 1
fi

DEFAULT_SSH_KEY_FILE="${INSTALL_YAMLS_DIR}/out/edpm/ansibleee-ssh-key-id_rsa"

if [ -n "${SSH_KEY_FILE}" ] && [ "${SSH_KEY_FILE}" != "${DEFAULT_SSH_KEY_FILE}" ] && ! ( [ -f "${SSH_KEY_FILE}" ] && [ -f "${SSH_KEY_FILE}.pub" ] ); then
    echo "Error: '${SSH_KEY_FILE}' or '${SSH_KEY_FILE}.pub' missing"
    return 1
fi


function generate_key {
    OUTPUT_DIR="${INSTALL_YAMLS_DIR}/out/edpm"

    SSH_REL_PATH="$(realpath -m --relative-to=${OUTPUT_DIR} ${SSH_KEY_FILE})"

    OUTPUT_DIR="${OUTPUT_DIR}" \
        SSH_KEY_FILE="${SSH_REL_PATH}" \
        ${INSTALL_YAMLS_DIR}/devsetup/scripts/gen-ansibleee-ssh-key.sh
}


function get_pci_type {
    if [ -z "${SRIOV_CAPABLE}" ]; then
        PCI_INFO="$(ssh ${SSH_ARGS} ${REMOTE_EDPM_IP} sudo lspci -v -d ${PCI_VENDOR_ID}:${PCI_PRODUCT_ID})"
        if [ $? -eq 1 ]; then
          echo "Error: Could not discover the type of PCI device by doing SSH into remote host"
          return 1
        fi
        if [[ "${PCI_INFO}" =~ 'SR-IOV' ]]; then
            SRIOV_CAPABLE=true
        else
            SRIOV_CAPABLE=false
        fi
    fi
    if [ "${SRIOV_CAPABLE}" == "true" ]; then
        echo 'type-PF'
    else
        echo 'type-PCI'
    fi
}


function gen_edpm_config {
    # Determine if it's a type-PF or type-PCI device
    PCI_TYPE=$(get_pci_type) || return $?
    sed "s/\${VENDOR_ID}/${PCI_VENDOR_ID}/g;s/\${PRODUCT_ID}/${PCI_PRODUCT_ID}/g;s/\${PCI_TYPE}/${PCI_TYPE}/g" ./templates/nova-compute.conf > ./out/nova-compute.conf

    mkdir -p out/preprovisioned

    BASE_DATAPLANE_YAML="$(realpath -m --relative-to=$(realpath ./out/preprovisioned) ${INSTALL_YAMLS_DIR}/out/operator/openstack-operator/config/samples/dataplane/base)"

    # Generate RH secrets if necessary
    KUSTOMIZATION_FILE=kustomization.yaml
    if [[ "${USE_UPSTREAM}" != 'true' ]]; then
      REGISTRY_DATA=$(echo -n "{\"registry.redhat.io\": {\"${RHR_USERNAME}\": \"${RHR_PASSWORD}\"}}" | base64 -w0)
      sed "s/\${SM_USERNAME}/$(echo -n ${SM_USERNAME} | base64 -w0)/g;s/\${SM_PASSWORD}/$(echo -n ${SM_PASSWORD} | base64 -w0)/g;s/\${REGISTRY_DATA}/${REGISTRY_DATA}/g" ./templates/preprovisioned/secrets.yaml > ./out/preprovisioned/secrets.yaml

      KUSTOMIZATION_FILE=kustomization-rh.yaml
    fi

    sed "s#\${BASE_DATAPLANE_YAML}#${BASE_DATAPLANE_YAML}#g;s#\${KERNEL_ARGS}#${EDPM_KERNEL_ARGS}#g;s#\${SECRETS}#${SECRETS}#g" "./templates/preprovisioned/${KUSTOMIZATION_FILE}" > ./out/preprovisioned/kustomization.yaml
    sed "s/\${TUN_IP}/${TUN_LOCAL_IP}/g;s/\${GNV_ID}/${GNV_ID}/g;s/\${TUN_NAME}/${TUN_NAME}/g;s/\${MTU}/${MTU}/g" ./templates/preprovisioned/tunneling.yaml > ./out/preprovisioned/tunneling.yaml
    sed "s/\${DNS_SERVER}/${INET_DNS_SERVER}/g" ./templates/preprovisioned/fixdns.yaml > ./out/preprovisioned/fixdns.yaml
    sed "s/\${DNS_SERVER}/${INET_DNS_SERVER}/g" ./templates/preprovisioned/os-net-config-template.yaml > ./out/preprovisioned/os-net-config-template.yaml

    cp ./templates/preprovisioned/blacklist.yaml ./out/preprovisioned/
}


function wait_mc_applied {
  echo 'Waiting for the cluster to begin updating'
  while ! oc wait mcp master --for condition=Updating; do sleep 10; done
  echo 'Waiting for the cluster to finish'
  while ! oc wait mcp master --for condition=Updated; do sleep 10; done
}


function change_cluster_mtu {
    # We need to set the "machine" part without changes or changes will be ignored
    echo 'Requesting the migration of the cluster MTU'
    CLUSTER_MTU="$((${MTU}-100))"
    oc patch Network.operator.openshift.io cluster --type=merge \
        --patch "{\"spec\": { \"migration\": { \"mtu\": { \"network\": { \"from\": 1400, \"to\": ${CLUSTER_MTU} }, \"machine\": {\"from\": 1500, \"to\": 1500} } } } }"

    wait_mc_applied

    echo 'Finalizing the migration of the cluster MTU'
    oc patch Network.operator.openshift.io cluster --type=merge --patch "{\"spec\": { \"migration\": null, \"defaultNetwork\":{ \"ovnKubernetesConfig\": { \"mtu\": ${CLUSTER_MTU} }}}}"

    wait_mc_applied
}


function gen_ctl_config {
    # Determine if it's a type-PF or type-PCI device
    PCI_TYPE=$(get_pci_type) || return $?
    sed "s/\${VENDOR_ID}/${PCI_VENDOR_ID}/g;s/\${PRODUCT_ID}/${PCI_PRODUCT_ID}/g;s/\${PCI_TYPE}/${PCI_TYPE}/g" "${CTL_TEMPLATE}" > out/kustomization.yaml
    sed "s/\${MTU}/${MTU}/g;s/\${VLAN_MTU}/${VLAN_MTU}/g;s/\${IP_ADDRESS_PREFIX}/${IP_ADDRESS_PREFIX}/g" "${NETCONFIG_TEMPLATE}" > out/netconfig.yaml

    oc kustomize ./out > ./out/openstack-deployment.yaml
}
